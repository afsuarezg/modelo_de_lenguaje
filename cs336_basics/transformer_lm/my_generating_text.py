#!/usr/bin/env python3

def decoding(max_tokens:int, temperature:float, top_threshold:float):
    """
    Implement a function to decode from your language model. We recommend that you support the following features: 
        Generate completions for a user-provided prompt (i.e., take in some x1...t and sample a completion until you hit a <|endoftext|> token).
        Allow the user to control the maximum number of generated tokens.
        Given a desired temperature value, apply softmax temperature scaling to the predicted next-word distributions before sampling.
        Top-p sampling (Holtzman et al., 2020; also referred to as nucleus sampling), given a user-specified threshold value.

    """
    pass
    
    
